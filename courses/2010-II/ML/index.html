<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html lang="en"><head>















<meta http-equiv="content-type" content="text/html; charset=ISO-8859-1"><title>Machine Learning</title>

<link type="text/css" href="../../courses.css" rel="stylesheet"></head><body>
<h1>Machine Learning<br>
<small>Maestría en Ingeniería -
Ingeniería de
Sistemas y Computación</small></h1>
<br>
<table style="text-align: left; background-color: rgb(255, 255, 255); width: 100%;" border="0" cellpadding="2" cellspacing="2">
<tbody>
<tr>
<td style="text-align: left; vertical-align: top; background-color: rgb(255, 255, 255);">20010-II<br>
<a href="http://dis.unal.edu.co/">Departamento de
Ingeniería de
Sistemas e Industrial</a><br>
<a href="http://www.unal.edu.co/">Universidad
Nacional de Colombia</a></td>
<td style="text-align: right; vertical-align: top; background-color: rgb(255, 255, 255);"><span style="font-weight: bold;">&nbsp;</span><br>
<a href="http://dis.unal.edu.co/%7Efgonza">Ing.
Fabio A.
González O., Ph.D. </a><br>
Of. 114, Edif. Nuevo de Ingeniería<br>
fagonzalezo_at_unal.edu.co</td>
</tr>
</tbody>
</table>
<h2>Contents</h2>
<ul>
<li><a href="#Descripci%F3n_del_curso_">Course
description</a></li>
<li><a href="#talleres_proyectos">Assignments</a></li>
<li><a href="#Material_de_apoyo_y_recursos">Resources</a></li>
<li><a href="lista.pdf">Grades</a>&nbsp;</li>
<ul>
</ul>
</ul>
<h2><a name="Descripción_del_curso_"></a>Course
Description </h2>
<h3>Objective</h3>
<div style="text-align: justify;">The main goal of Machine
Learning
(ML) is the development of systems that are able to autonomously change
their behavior based on experience. ML offers some of the more
effective techniques for knowledge discovery in large data sets. ML has
played a fundamental role in areas such as bioinformatics, information
retrieval, business intelligence and autonomous vehicle development.<br>
<br>
The main goal of this course is to study the computational,
mathematical and statistical foundations of ML, which are essential for
the theoretical analysis of existing learning algorithms, the
development of new algorithms and the well-founded application of ML to
solve real-world problems.
</div>
<h3>Methodology</h3>
<ul>
<li>Professor's lectures on fundamental topics </li>
<li>Practical assignments and exercises to be solved
by&nbsp;students&nbsp;</li>
<li>Technical papers' review and presentation by students</li>
<li>Final&nbsp;project</li>
<li>Written and practical tests. Students must show a
good&nbsp;grasp of concepts and skills covered in the course.</li>
</ul>
<h3>Contents</h3>
<table style="width: 85%; text-align: left; margin-left: auto; margin-right: auto;" border="0" cellpadding="2" cellspacing="2">
<tbody>
<tr>
<th>Topic</th>
<th>Material</th>
<th>Assignments</th>
<th>Presentations</th>
</tr>
<tr>
<td><small>1. Introduction</small><br>
</td>
<td><small><a href="introduction.pdf">Brief Introduction to ML</a><br>
[Mit97] Cap 1<br>
[Alp04] Cap 1,2<br>
[DHS00] A.1, A.2<br>
</small></td>
<td><a href="assign1.pdf"><small>Assignment 1</small></a><br>
</td>
<td><small><span style="font-weight: bold;">Videos:</span><a href="http://video.google.com/videoplay?docid=8594517128412883394#docid=8719876587754396524"><br>
The great robot race</a><br>
      <a href="http://video.google.com/videoplay?docid=8594517128412883394#">Wining the Darpa Grand Challenge</a><br><a href="http://videolectures.net/bootcamp07_guyon_itml/">Introduction to Machine Learning</a><br><span style="font-weight: bold;">Review:<br></span><a href="http://videolectures.net/bootcamp07_keller_bss/">Linear Algebra and Probability Review</a><span style="font-weight: bold;"></span><span style="text-decoration: underline;"> </span>(part 1 Linear Algebra, part 2 Probability)</small><small><a href="http://videolectures.net/bootcamp07_guyon_itml/"><br></a></small></td>
</tr>
<tr>
<td><small>2.&nbsp;Bayesian decision theory<br>
2.1 A review of probability theory<br>
2.2 Classification<br>
2.3 Lost and risk<br>
2.4 Naive Bayes classifier<br>
2.5 Bayesian Networks<br>
2.6 Maximum likelihood estimation<br>
2.7 Bayesian estimation<br>
2.8 Parametric Classification<br>
2.9 Expectation Maximization</small>
</td>
<td><small>[Alp04] <a href="http://www.cmpe.boun.edu.tr/%7Eethem/i2ml/slides/v1-1/i2ml-chap3-v1-1.pdf">Chap
3</a>, 
</small><small><a href="http://www.cmpe.boun.edu.tr/%7Eethem/i2ml/slides/v1-1/i2ml-chap4-v1-1.pdf">Chap
4</a>,<br><a href="http://www.cmpe.boun.edu.tr/%7Eethem/i2ml/slides/v1-1/i2ml-chap7-v1-1.pdf">Chap
7</a> (Sect. 7.4)&nbsp;<br>
[DHS00] Chap 3<br>
[<a href="reading.html">Tenenbaum06</a>]</small>
</td>
<td><a href="assign2.pdf"><small>Assignment 2</small></a><br>
      <small>(</small><a href="data.txt"><small>dataset</small></a><small>)<br>
</small><a href="assign3.pdf"><small>Assignment 3</small></a><br>

      <big>
      </big></td>
<td><small><span style="font-weight: bold;">Videos:</span></small><br>
      <a href="http://scpro.streamuk.com/uk/player/Default.aspx?wid=7739"><small>Embracing uncertainty: the new machine intelligence</small></a><br>
      <small style="font-weight: bold;">Presentations:<br>
      </small><small>Fabián Giraldo [<a href="reading.html">Bishop07</a>]<br>
Juan Gabriel Bobadilla [<a href="reading.html">Bishop08</a>]<br>
      <br>
      </small>
</td>
</tr>
<tr>
<td><small>3. Kernel methods<br>
3.1 The kernel trick <br>
3.2 Kernel ridge regression <br>
3.3 Kernel functions <br>
3.4 Other kernel Algorithms <br>
3.5 Kernels in complex structured data
</small></td>
<td><small>[SC04] Chap 2<br>
</small><small><a href="file:///Users/fgonza/Documents/public_html/courses/2009-I/ml/kernels.pdf">Introd. to kernel methods</a></small><br>
      <small><br>
      </small></td>
<td><a href="assign3.pdf"><small><br>
</small></a><big>
      </big></td>
<td><small style="font-weight: bold;">Presentations:<br>
      </small><small>Angélica Veloza&nbsp; [<a href="reading.html">Quadrianto10</a>]<br>

Juan Guillermo Carvajal&nbsp; [<a href="reading.html">Chen09</a>]<br>

      </small>
</td>
</tr>
<tr>
<td><small>4. Support vector learning<br>
4.1 Support vector machines<br>4.2 Regularization and model complexity<br>
4.3 Risk and empirical risk<br>4.4&nbsp;SVM variations
</small></td>
<td><small>[Alp04] </small><small><a href="http://www.cmpe.boun.edu.tr/%7Eethem/i2ml/slides/v1-1/i2ml-chap4-v1-1.pdf">Chap
4</a> (Sect. 4.3, 4.7, 4.8), <a href="http://www.cmpe.boun.edu.tr/%7Eethem/i2ml/slides/v1-1/i2ml-chap10-v1-1.pdf">Chap 10</a> (Sect. 10.9)<br><a href="http://axiom.anu.edu.au/%7Edaa/courses/GSAC6017/tekbac_4.pdf">An introduction to ML</a>, Smola<br><a href="http://www1.cs.columbia.edu/%7Ekathy/cs4701/documents/jason_svm_tutorial.pdf">Support Vector Machine Tutorial</a>, Weston<br><br><br> </small>
</td>
<td><a href="assign4.pdf"><small>Assignment 4</small></a><br>
</td>
<td><small style="font-weight: bold;">Presentations:<br>
      </small><small>Carlos Arias </small><small>[<a href="reading.html">Finley05</a>]</small><br>
      <small>
Alfredo Espitia [<a href="reading.html">Joachims09</a>] <br>
Rubén Manrique [<a href="reading.html">Smola04</a>]<br>

      </small>
</td>
</tr>
<tr>
<td><small>5. Performance evaluation<br>5.1 Performance evaluation in supervised learning<br>5.2 Performance evaluation in unsupervised learning<br>5.3 Hypothesis testing</small><br>
</td>
<td><small>[Alp04] </small><a href="http://www.cmpe.boun.edu.tr/%7Eethem/i2ml/slides/v1-1/i2ml-chap14-v1-1.pdf"><small>Cap 14</small></a><small><br>[TSK05] <a href="http://www-users.cs.umn.edu/%7Ekumar/dmbook/dmslides/chap8_basic_cluster_analysis.pdf">Chap 8</a> (Sect. 8.5)</small>
</td>
<td><br>
</td>
<td><small style="font-weight: bold;">Presentations:<br>
      </small><small>Angel Cruz [<a href="reading.html">Dietterich98</a>] <br>
Arles Rodríguez [<a href="reading.html">Domingos99</a>] <br>
      </small>
</td>
</tr>
<tr>
<td><small>6. Combining multiple classifiers<br>6.1 Voting<br>6.2 Error correcting codes<br>6.3 Bagging<br>6.4 Boosting</small></td>
<td><small>[Alp04] </small><a href="http://www.cmpe.boun.edu.tr/%7Eethem/i2ml/slides/v1-1/i2ml-chap15-v1-1.pdf"><small>Cap 15</small></a>
</td>
<td><br>
</td>
<td><small style="font-weight: bold;">Presentations:<br>
      </small><small>Juan Carlos León [<a href="reading.html">Viola04</a>]<br>
Carlos Sierra [<a href="reading.html">Breiman01</a>]<br>
      </small>
</td>
</tr>
<tr>
<td><small>7. Learning on complex-structured and non-structured data<br>
7.1 Sructured output prediction<br>
7.2 Markov Random Fields<br>
7.3 Structured SVM<br>
</small></td>
<td><br>
</td>
<td><br>
</td>
<td><small style="font-weight: bold;">Presentations:<br>
      </small><small>Javier Sandoval </small><small style="font-weight: bold;"><br>
      </small><small>Leandro Liu&nbsp; [<a href="reading.html">Cabestany05</a>]</small><small style="font-weight: bold;">
      </small>
</td>
</tr><tr><td><small>Final Exam: Nov 23rd<br>
</small></td><td><br>
</td><td><br>
</td><td><br>
</td></tr><tr><td><small>Project:<small><br>
      </small></small><small>- Proposal: Nov 9th<br>
- Final: Nov 30th<br>
      </small></td><td><br>
</td><td><br>
</td><td><br>
</td></tr>
</tbody>
</table>
<br>
<br>
<h3>Grading</h3>
<ul>
<li>Assignments 40% </li>
<li>Exams 30%</li>
<ul></ul>
<li>Presentation 15%</li>
<li>Final project 15%</li>
</ul>
<h3>References</h3>
<ul>
<li>[Alp04] Alpaydin, E. 2004 Introduction to Machine Learning
(Adaptive Computation and Machine Learning). The MIT Press.</li>
  <li>[Bis06] Bishop, C. 2006 Pattern Recognition and Machine Learning. Springer-Verlag.<br>
  </li>

<li>[Mit97] Mitchell, T. M. 1997 Machine Learning. 1st.
McGraw-Hill
Higher Education.</li>
<li>[DHS00] Duda, R. O., Hart, P. E., and Stork, D. G. 2000
Pattern
Classification (2nd Edition). Wiley-Interscience.</li>
<li>[HTF01] Hastie, T. and Tibshirani, R. and Friedman. 2001
The
elements of
statistical learning: data mining, inference, and prediction. Springer.</li>
<li>[SC04] Shawe-Taylor, J. and Cristianini, N. 2004 Kernel
Methods
for Pattern Analysis. Cambridge University Press.</li>
<li>[TSK05] Pang-Ning Tan, Michael Steinbach, Vipin Kumar,
&nbsp;2005, Introduction to Data Mining, Addison-Wesley.</li>
<li>[OCW-ML] <a href="http://ocw.mit.edu/OcwWeb/Electrical-Engineering-and-Computer-Science/6-867Machine-LearningFall2002/CourseHome/index.htm">6.867
Machine Learning</a>, Fall 2002, &nbsp;MIT OpenCourseWare.</li><li>[CST00]
Cristianini, N. and Shawe-Taylor, J., 2000, An introduction to support
Vector Machines: and other kernel-based learning methods,, Cambridge Univ Press. </li><li>[SS02] Scholkopf, B. and Smola, A.J., 2002, Learning with kernels, MIT Press.</li><li>[Bak07] Bakir, G. (Ed), 2007, Predicting Structured Data, MIT Press.</li>
</ul>
<h4>Additional references</h4>
<ul>
<li>MacKay, "Information Theory, Inference, and Learning
Algorithms", 2003. (<a href="http://www.inference.phy.cam.ac.uk/mackay/itila/book.html">on-line
version</a>)</li>
</ul>
<ul>
</ul>
<a href="#inicio">Back</a><br>
<br>
<h2><a name="talleres_proyectos"></a>Assignments</h2>
<ul>
  <li><a href="assign1.pdf">Assignment 1</a>: Probability review</li>
  <li><a href="assign2.pdf">Assignment 2</a>: Bayesian Decision Theory (I) (<a href="data.txt">dataset</a>)</li>
  <li><a href="assign3.pdf">Assignment 3</a>: Bayesian Decision Theory (II)</li>
  <li><a href="assign4.pdf">Assignment 4</a>: Kernel Methods and SVM's<br>
  </li>



</ul>
<span style="text-decoration: underline;"><br>
Back</span><br>
<h2><a name="Material_de_apoyo_y_recursos"></a>Resources
&nbsp;</h2>
<ul>
<li><a href="reading.html">Reading list</a></li><li><a href="http://www.cs.waikato.ac.nz/ml/weka/">WEKA</a>:
a collection of machine learning algorithms for data mining tasks based
on Java.</li>
<li><a href="http://rapid-i.com/content/blogcategory/10/69/">RapidMiner</a>:
Data mining tool based on Java.</li>
</ul>
<ul>
</ul>
<ul>
</ul>
<ul>
</ul>
<span style="text-decoration: underline;">Back</span><br>
</body></html>