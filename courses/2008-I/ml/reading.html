<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html lang="en"><head><title>ML Reading List</title>

<meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<style type="text/css">
body { font-size: 12px; font-family: Arial, sans-serif; }
dt { margin-top: 1em; font-weight: bold; }
</style></head>
<body><h1>Reading List</h1>

<h3 style="text-align: right;"><a href="index.html">Machine
Learning</a><br>
2008-I</h3>
<hr style="width: 100%; height: 2px; margin-left: auto; margin-right: 0px;">
<h3>Bayesian decision theory</h3>
<dl>
<dt>[Tenenbaum06]</dt>
<dd>Tenenbaum, J. B.; Griffiths, T. L. &amp; Kemp, C.</dd>
<dd><a href="http://web.mit.edu/cocosci/Papers/tics-theories-reprint.pdf">Theory-based Bayesian models of inductive learning and
reasoning</a></dd>
<dd><em>Trends in Cognitive Sciences,</em></dd>
<dd><b>2006</b><i>, 10</i>, 309-318</dd>
<dt>[Dietterich02]</dt>
<dd>Dietterich, T. G.</dd>
<dd><a href="http://web.engr.oregonstate.edu/%7Etgd/publications/mlsd-ssspr.pdf">Machine Learning for Sequential Data: A Review</a></dd>
<dd><em>Structural, Syntactic, and Statistical Pattern
Recognition: Joint Iapr International Workshops Sspr 2002 and Spr 2002,
Windsor, Ontario, Canada, August 6-9, 2002: Proceedings,</em></dd>
<dd><b>2002</b></dd><dt>[Friedman99]</dt>
<dd>Friedman, N.; Getoor, L.; Koller, D. &amp; Pfeffer, A.</dd>
<dd><a href="http://luci.ics.uci.edu/predeployment/websiteContent/weAreLuci/biographies/faculty/djp3/LocalCopy/friedman99.pdf">Learning probabilistic relational models</a></dd>
<dd><em>Proceedings of the Sixteenth International Joint
Conference on Artificial Intelligence,</em></dd>
<dd><b>1999</b>, 1300-1309</dd>
<dt><em></em>[Goldenberg05]</dt>
<dd>Goldenberg, A. &amp; Moore, A.</dd>
<dd><a href="http://www.cs.cmu.edu/%7Eanya/papers/link-kdd05.pdf">Bayes Net Graphs to Understand Coauthorship Networks</a></dd>
<dd><em>KDD Workshop on Link Discovery: Issues,
Approaches and Applications,</em></dd>
<dd><b>2005</b></dd>
</dl><h3>Kernel methods</h3><dl><dt>[Grauman05]</dt><dd>Grauman, K., and T. Darrell.<span style="font-weight: bold;"></span></dd><dd><a href="http://publications.csail.mit.edu/tmp/MIT-CSAIL-TR-2005-017.pdf">Pyramid match kernel: Discriminative classification with sets of image features.</a><span style="font-style: italic;"></span></dd><dd><span style="font-style: italic;">MIT Computer Science and Artificial Intelligence Laboratory Technical Report, MIT-CSAIL-TR-2005-017</span></dd><dd>2005. </dd></dl><dl><dt>[Leslie02]</dt><dd>Leslie, C., E. Eskin, and W. S. Noble.&nbsp;</dd><dd><a href="http://psb.stanford.edu/psb-online/proceedings/psb02/leslie.pdf">The spectrum kernel: A string kernel for SVM protein classification.</a><span style="font-style: italic;"></span></dd><dd><span style="font-style: italic;">In Proceedings of the 2002 Pacific Symposium on Biocomputing</span></dd><dd>2002<br></dd></dl><dl><dt>[Lodhi02]</dt><dd>Lodhi, H., C. Saunders, J. Shawe-Taylor, N. Cristianini, and C. Watkins.&nbsp;</dd><dd><a href="http://jmlr.csail.mit.edu/papers/volume2/lodhi02a/lodhi02a.pdf">Text classification using string kernels.&nbsp;</a><span style="font-style: italic;"></span></dd><dd><span style="font-style: italic;">The Journal of Machine Learning Research 2:419-444.</span></dd><dd>2002<br></dd></dl><h3>Regularization and model complexity</h3><dl><dt>[Lawrence96]<span style="font-weight: bold;"></span></dt><dd><span style="font-weight: bold;"></span>Lawrence, Steve, C. Lee Giles, and A.C. Tsoi.&nbsp;<br><a href="https://drum.umd.edu/dspace/handle/1903/809?mode=simple">What Size Neural Network Gives Optimal Generalization? Convergence Properties of Backpropagation.</a>&nbsp;<br>UM Computer Science Department. University of Maryland,&nbsp;UMIACS-TR-96-22<br>1996</dd></dl><dl><dt>[Mehta95]</dt><dd>Mehta, M., J. Rissanen, and R. Agrawal.&nbsp;</dd><dd><a href="http://www.cse.iitb.ac.in/dbms/Data/Papers-Other/Mining/kdd95.ps.gz.">MDL-based decision tree pruning.</a></dd><dd>In Proceedings of KDD95<br>1995</dd></dl><dl><dt>[Roberts00]</dt><dd>Roberts, S., and H. Pashler.&nbsp;</dd><dd><a href="http://repositories.cdlib.org/cgi/viewcontent.cgi?article=2537&amp;context=postprints">How persuasive is a good fit? A comment on theory testing. </a><br>Psychological Review 107, no. 2:358-367<br>2000</dd></dl><h3>Performance evaluation</h3><dl><dt>[Domingos99]</dt><dd>Domingos, P.&nbsp;</dd><dd><a href="http://elvis.slis.indiana.edu/irpub/KDD/1999/pdf19.pdf">MetaCost: a general method for making classifiers cost-sensitive.&nbsp;</a></dd><dd>In Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining, p. 155-164</dd><dd> 1999</dd></dl><dl><dt>[Hand01]</dt><dd>Hand, David J., and Robert J. Till.&nbsp;</dd><dd><a href="http://dx.doi.org/10.1023/A:1010920819831">A Simple Generalisation of the Area Under the ROC Curve for Multiple Class Classification Problems.&nbsp;</a></dd><dd>Machine Learning 45, no. 2:171-186.</dd><dd> 2001</dd></dl><dl><dt>[Japkowicz02]</dt><dd>Japkowicz, N.&nbsp;</dd><dd><a href="http://www.site.uottawa.ca/%7Enat/Papers/ida-journal-final.ps.gz">The class imbalance problem: A systematic study.&nbsp;</a></dd><dd>Intelligent Data Analysis, 6(5), p.429-449.<br>2002</dd></dl><h3>Combining multiple classifiers</h3><dl><dt>[Dietterich00]&nbsp;</dt><dd>Dietterich, T. G.&nbsp;</dd><dd><a href="http://140.109.73.167/file/Paper/Boosting/ref51.pdf">An Experimental Comparison of Three Methods for Constructing Ensembles of Decision Trees: Bagging, Boosting, and Randomization.</a> Machine Learning 40, no. 2: 139-157.&nbsp;</dd><dd>2000<span style="font-weight: bold;"></span></dd></dl><dl><dt>[Mason00]&nbsp;</dt><dd>Mason, L., J. Baxter, P. Bartlett, and M. Frean.&nbsp;</dd><dd><a href="http://www.lsmason.com/papers/NIPS00-DOOMII.pdf">Boosting algorithms as gradient descent.&nbsp;</a></dd><dd>In Advances in Neural Information Processing Systems, 12:512-518.&nbsp;</dd><dd> 2000</dd></dl><dl><dt>[Oza05]</dt><dd>Oza, N.&nbsp;&nbsp;</dd><dd><a href="http://tc.arc.nasa.gov/people/oza/publications/files/oza05.pdf.">Online bagging and boosting.&nbsp;</a></dd><dd>In 2005 IEEE International Conference on Systems, Man and Cybernetics&nbsp;&nbsp;</dd><dd>2005</dd></dl><h3>Clustering and density estimation</h3>
</body></html>